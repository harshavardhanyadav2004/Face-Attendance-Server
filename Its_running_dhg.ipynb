{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshavardhanyadav2004/Face-Attendance-Server/blob/main/Its_running_dhg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwfOJRd_mvaE",
        "outputId": "ef5932b4-fe2a-424e-81da-735a92c8b00a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.7)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (19.24.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_recognition) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition) (9.4.0)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566170 sha256=89ec6cf293227eb62415d8fc861cf86f082a46a17df8a8ae954b96d2a8b051b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/eb/cf/e9eced74122b679557f597bb7c8e4c739cfcac526db1fd523d\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face_recognition\n",
            "Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n"
          ]
        }
      ],
      "source": [
        "pip install face_recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLKHVlM5lZlo",
        "outputId": "b408e848-83ae-4b03-8512-0bf519c2dc4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.1.6-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.1.6\n"
          ]
        }
      ],
      "source": [
        "pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHQ3pD9qlgu6",
        "outputId": "8750ab5a-302a-437b-eb28-fe691b4cf953"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flask-bootstrap\n",
            "  Downloading Flask-Bootstrap-3.3.7.1.tar.gz (456 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.4/456.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.10/dist-packages (from flask-bootstrap) (2.2.5)\n",
            "Collecting dominate (from flask-bootstrap)\n",
            "  Downloading dominate-2.9.1-py2.py3-none-any.whl (29 kB)\n",
            "Collecting visitor (from flask-bootstrap)\n",
            "  Downloading visitor-0.1.3.tar.gz (3.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-bootstrap) (3.0.2)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-bootstrap) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-bootstrap) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-bootstrap) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=0.8->flask-bootstrap) (2.1.5)\n",
            "Building wheels for collected packages: flask-bootstrap, visitor\n",
            "  Building wheel for flask-bootstrap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flask-bootstrap: filename=Flask_Bootstrap-3.3.7.1-py3-none-any.whl size=460120 sha256=e97e39e1353f0f33837e2d77a48fcfec17691694404963ae806e17b976b89c39\n",
            "  Stored in directory: /root/.cache/pip/wheels/6f/33/ad/26540e84a28334e5dfeda756df270f95353779f03bc5cf40d4\n",
            "  Building wheel for visitor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visitor: filename=visitor-0.1.3-py3-none-any.whl size=3928 sha256=65a55df6ce9763eab585df9191d9a894851599f4938448a671cc575170fc74c6\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/31/99/2ec5b4459cac4d801d6201d501a354366d180afc9f8bb2d333\n",
            "Successfully built flask-bootstrap visitor\n",
            "Installing collected packages: visitor, dominate, flask-bootstrap\n",
            "Successfully installed dominate-2.9.1 flask-bootstrap-3.3.7.1 visitor-0.1.3\n"
          ]
        }
      ],
      "source": [
        "pip install flask-bootstrap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TWSA6fZ2fkeT"
      },
      "outputs": [],
      "source": [
        "port_no = 5000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kAWAAg9UgSYa"
      },
      "outputs": [],
      "source": [
        "import face_recognition as fr\n",
        "import cv2\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "class FaceRecognition:\n",
        "    def __init__(self, frames_dir, known_face_encodings, student_dic):\n",
        "        self.frames_dir = frames_dir\n",
        "        self.known_face_encodings = known_face_encodings\n",
        "        self.students = student_dic\n",
        "\n",
        "        csm_students = list(self.students.keys())\n",
        "\n",
        "    def load_image_paths(self):\n",
        "        image_paths = [os.path.join(self.frames_dir, filename) for filename in os.listdir(self.frames_dir) if filename.lower().endswith('.jpg')]\n",
        "        return image_paths\n",
        "\n",
        "    def load_new_student(path):\n",
        "        x_image = fr.load_image_file(path)\n",
        "        print(x_image)\n",
        "        x_face_encoding = fr.face_encodings(x_image)[0]\n",
        "        return x_face_encoding\n",
        "\n",
        "    def find_faces(self, image_paths):\n",
        "        face_locations = []\n",
        "        face_encodings = []\n",
        "\n",
        "        for path in image_paths:\n",
        "            frame = fr.load_image_file(path)\n",
        "            rgb_frame = frame[:, :, ::-1]  # Convert BGR to RGB\n",
        "\n",
        "            face_locations = fr.face_locations(rgb_frame, number_of_times_to_upsample=1, model='hog')\n",
        "            face_encodings_for_frame = fr.face_encodings(frame, face_locations)\n",
        "\n",
        "            face_encodings.extend(face_encodings_for_frame)\n",
        "\n",
        "        return face_encodings\n",
        "\n",
        "\n",
        "\n",
        "    def cosine_similarity(self, vector_a, vector_b):\n",
        "        vector_a = np.array(vector_a, dtype=float)\n",
        "        vector_b = np.array(vector_b, dtype=float)\n",
        "        dot_product = np.dot(vector_a, vector_b)\n",
        "        magnitude_a = np.linalg.norm(vector_a)\n",
        "        magnitude_b = np.linalg.norm(vector_b)\n",
        "\n",
        "        if magnitude_a == 0 or magnitude_b == 0:\n",
        "            return 0\n",
        "\n",
        "        cosine_similarity_value = dot_product / (magnitude_a * magnitude_b)\n",
        "        return cosine_similarity_value\n",
        "\n",
        "    def compare_faces(self, video_face_encodings):\n",
        "        similarities = []\n",
        "        student_names = []\n",
        "        csm_students = list(self.students.keys())\n",
        "\n",
        "        for y in video_face_encodings:\n",
        "            nec = [self.cosine_similarity(y, x) for x in self.known_face_encodings]\n",
        "            similarities.append(nec)\n",
        "\n",
        "        for x in similarities:\n",
        "            student_names.append(csm_students[np.argmax(x)])\n",
        "\n",
        "        return list(set(student_names))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "AuPTX3EegYOF",
        "outputId": "995d629a-b800-4fd0-9a14-b119ad2a0338"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'if __name__ == \"__main__\":\\n    directory = \"Frames\"\\n    video_path = \"video.mp4\"\\n\\n    if not os.path.exists(directory):\\n        os.makedirs(directory)\\n\\n    preprocessor = VideoPreprocessor(directory, video_path)\\n    preprocessor.extract_frames_per_second()'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import face_recognition as fr\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "\n",
        "class VideoPreprocessor:\n",
        "    def __init__(self, directory, video_path):\n",
        "        self.directory = directory\n",
        "        self.video_path = video_path\n",
        "        self.fps = None\n",
        "        self.frame_count = 0\n",
        "        self.extracted_frame_count = 0\n",
        "\n",
        "    def empty_folder(self):\n",
        "        for file in os.listdir(self.directory):\n",
        "            file_path = os.path.join(self.directory, file)\n",
        "            if os.path.isfile(file_path):\n",
        "                os.remove(file_path)\n",
        "        return True\n",
        "\n",
        "    def extract_frames_per_second(self):\n",
        "        try:\n",
        "            cap = cv.VideoCapture(self.video_path)\n",
        "            if not cap.isOpened():\n",
        "                raise IOError(\"Error opening video!\")\n",
        "\n",
        "            self.fps = cap.get(cv.CAP_PROP_FPS)\n",
        "            if self.fps <= 0:\n",
        "                raise ValueError(\"Invalid FPS value.\")\n",
        "\n",
        "            if self.empty_folder():\n",
        "                while True:\n",
        "                    ret, frame = cap.read()\n",
        "\n",
        "                    if not ret:\n",
        "                        print(\"End of video reached.\")\n",
        "                        break\n",
        "\n",
        "                    # Extract one frame per second\n",
        "                    if self.frame_count % int(self.fps) == 0:\n",
        "                        filename = f\"{self.directory}/frame_{self.extracted_frame_count}.jpg\"\n",
        "                        cv.imwrite(filename, frame)\n",
        "                        self.extracted_frame_count += 1\n",
        "\n",
        "                    self.frame_count += 1\n",
        "\n",
        "                print(f\"Extracted {self.extracted_frame_count} frames to {self.directory}\")\n",
        "\n",
        "        except IOError as e:\n",
        "            print(f\"IOError: {e}\")\n",
        "        except ValueError as e:\n",
        "            print(f\"ValueError: {e}\")\n",
        "        finally:\n",
        "            cap.release()\n",
        "\n",
        "# Example usage\n",
        "'''if __name__ == \"__main__\":\n",
        "    directory = \"Frames\"\n",
        "    video_path = \"video.mp4\"\n",
        "\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    preprocessor = VideoPreprocessor(directory, video_path)\n",
        "    preprocessor.extract_frames_per_second()'''\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgR3KSiSZ6gW",
        "outputId": "0f14d45e-a764-43f3-f522-059251ae142d"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://af74-34-68-47-86.ngrok-free.app\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of video reached.\n",
            "Extracted 3 frames to /content/Frames\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [01/May/2024 16:46:16] \"POST /uploadDetailedVideo HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['21981a4465']\n",
            "{'21981a4465': 'Sudha Sankar rao', '21981a4466': 'Harsha Vardhan'}\n",
            "['21981a4466']\n",
            "{'presentees': [{'name': 'Sudha Sankar rao', 'roll': '21981a4465'}], 'absentees': [{'name': 'Harsha Vardhan', 'roll': '21981a4466'}]}\n",
            "End of video reached.\n",
            "Extracted 3 frames to /content/Frames\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [01/May/2024 16:50:08] \"POST /uploadDetailedVideo HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['21981a4466']\n",
            "{'21981a4465': 'Sudha Sankar rao', '21981a4466': 'Harsha Vardhan'}\n",
            "['21981a4465']\n",
            "{'presentees': [{'name': 'Harsha Vardhan', 'roll': '21981a4466'}], 'absentees': [{'name': 'Sudha Sankar rao', 'roll': '21981a4465'}]}\n"
          ]
        }
      ],
      "source": [
        "from flask import *\n",
        "import os\n",
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"2fhOSoa9jSR3KoJHNOmgUultPE2_6jkfdizMSEioQtYY1Q35s\")\n",
        "public_url = ngrok.connect(5000).public_url\n",
        "import sqlite3\n",
        "import numpy as np\n",
        "new_List = []\n",
        "app = Flask(__name__)\n",
        "app.secret_key='I_AM_IRON_MAN'\n",
        "ALLOWED_EXTENSIONS = ['mp4']\n",
        "@app.route(\"/\")\n",
        "def index():\n",
        "    return render_template(\"newForm.html\")\n",
        "def allowed_file(filename):\n",
        "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
        "@app.route(\"/uploadStudents\",methods=[\"POST\",\"GET\"])\n",
        "def ImageUpload():\n",
        "    if request.method == 'POST':\n",
        "        name = request.form[\"Name\"]\n",
        "        roll = request.form[\"Roll\"]\n",
        "        image = request.files['Image']\n",
        "        image.save(image.filename)\n",
        "        print(image)\n",
        "        face_encoded = FaceRecognition.load_new_student(image)\n",
        "        new_List.append(face_encoded)\n",
        "        new_array = \"/\".join([str(i) for i in face_encoded])\n",
        "        if SelectFromTable(roll):\n",
        "            return jsonify(\"Already present in the database\")\n",
        "        with sqlite3.connect(\"Attendance.db\") as conn :\n",
        "            cursor = conn.cursor()\n",
        "            cursor.execute(\"INSERT INTO USERS (Name,Roll,Face_Encodings) VALUES (?,?,?)\",(name,roll,new_array))\n",
        "            conn.commit()\n",
        "        return jsonify(\"SuccessFully Uploaded\")\n",
        "@app.route(\"/uploadVideo\")\n",
        "def videoUpload():\n",
        "  return render_template(\"index.html\")\n",
        "@app.route(\"/uploadDetailedVideo\",methods = [\"POST\",\"GET\"])\n",
        "def detailedVideoUpload():\n",
        "    if 'video' not in request.files:\n",
        "        return  jsonify(\"No Video Found\")\n",
        "    video = request.files['video']\n",
        "    if video.filename == \"\":\n",
        "        return jsonify(\"No File Selected\")\n",
        "    if video and allowed_file(video.filename):\n",
        "        video.save(video.filename)\n",
        "        video_object = VideoPreprocessor(\"/content/Frames\",video_path=video.filename)\n",
        "        if video_object.empty_folder():\n",
        "            video_object.extract_frames_per_second()\n",
        "            studentdetails,known_encodings = fetchFromDataBase()\n",
        "            face_object = FaceRecognition(\"/content/Frames\",known_encodings,studentdetails)\n",
        "            new_image_paths = face_object.load_image_paths()\n",
        "            new_face_encodings = face_object.find_faces(new_image_paths)\n",
        "            attendees_list = face_object.compare_faces(new_face_encodings)\n",
        "            new_dictionary = joining_sequel_function(attendees_list)\n",
        "            return jsonify(new_dictionary)\n",
        "        return jsonify(\"Error in emptying the Folder\")\n",
        "    return jsonify(\"Invalid type in the File \")\n",
        "def joining_sequel_function(attendees_list):\n",
        "  with sqlite3.connect(\"Attendance.db\") as conn:\n",
        "    print(attendees_list)\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT * FROM USERS\")\n",
        "    all_attendees_list = { i[1] : i[0] for i in cursor }\n",
        "    print(all_attendees_list)\n",
        "    abseentees_list = [ i for i in all_attendees_list.keys() if i not in attendees_list ]\n",
        "    print(abseentees_list)\n",
        "    dictionary = {}\n",
        "    array_presents = []\n",
        "    array_absents  = []\n",
        "    for i in attendees_list:\n",
        "      array_presents.append({\"name\":all_attendees_list[i],\"roll\":i})\n",
        "    dictionary[\"presentees\"] = array_presents\n",
        "    for i in abseentees_list:\n",
        "      array_absents.append({\"name\":all_attendees_list[i],\"roll\":i})\n",
        "    dictionary[\"absentees\"] = array_absents\n",
        "    print(dictionary)\n",
        "    return dictionary\n",
        "def fetchFromDataBase():\n",
        "    with sqlite3.connect(\"Attendance.db\") as conn:\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"SELECT * FROM USERS\")\n",
        "        student_dict = {}\n",
        "        new_Face_Encodings = []\n",
        "        for i in cursor :\n",
        "            student_dict[i[1]] = i[0]\n",
        "            new_Face_Encodings.append(np.array([float(j) for j in i[2].split(\"/\") ]))\n",
        "    return student_dict,new_Face_Encodings\n",
        "@app.route(\"/generatePDF\",methods = [\"POST\",\"GET\"])\n",
        "def lastTouch():\n",
        "  if request.method == \"POST\":\n",
        "      get_text = request.form[\"textdata\"]\n",
        "      new_text_speech = generator(get_text)\n",
        "      return jsonify(new_text_speech)\n",
        "def createTable():\n",
        "    with sqlite3.connect(\"Attendance.db\") as conn:\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"CREATE TABLE USERS (Name VARCHAR(255), Roll VARCHAR(255), Face_Encodings TEXT(16000) , PRIMARY KEY(Roll))\")\n",
        "    print(\"created successfully\")\n",
        "def SelectFromTable(roll_no):\n",
        "    with sqlite3.connect(\"Attendance.db\") as conn:\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"SELECT * FROM USERS ORDER BY Roll\")\n",
        "        another_tuple = []\n",
        "        for i in cursor:\n",
        "            another_tuple.append(i[1])\n",
        "        if roll_no in another_tuple:\n",
        "            return True\n",
        "           # https://8950-35-185-178-154.ngrok-free.app\n",
        "    return False\n",
        "if __name__ == '__main__':\n",
        "    #createTable()\n",
        "    print(public_url)\n",
        "    app.run(port = port_no )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attendees_list=[\"21981a4465\"]\n",
        "with sqlite3.connect(\"Attendance.db\") as conn:\n",
        "    with sqlite3.connect(\"Attendance.db\") as conn:\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"SELECT * FROM USERS\")\n",
        "        student_dict = {}\n",
        "        new_Face_Encodings = []\n",
        "        for i in cursor :\n",
        "            student_dict[i[1]] = i[0]\n",
        "            new_Face_Encodings.append(np.array([float(j) for j in i[2].split(\"/\") ]))\n",
        "        print(student_dict,new_Face_Encodings)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0V_E2qXY8Lyh",
        "outputId": "a3bcf8ea-c84f-4a89-a2e2-f34e980cf6cb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'21981a4465': 'Sudha Sankar rao', '21981a4466': 'Harsha Vardhan'} [array([-0.13409157,  0.13800862,  0.05355558, -0.05370569, -0.06824048,\n",
            "       -0.04218274, -0.03351473, -0.10006957,  0.17636909, -0.09130377,\n",
            "        0.23674241, -0.08588597, -0.20948203, -0.12220045,  0.02624761,\n",
            "        0.09816415, -0.13268098, -0.1231949 , -0.02000012, -0.14298905,\n",
            "        0.02302869,  0.01699419,  0.02203441,  0.02601515, -0.19595644,\n",
            "       -0.3748391 , -0.09661537, -0.13424091, -0.02401798, -0.05964912,\n",
            "       -0.01487449,  0.06595365, -0.1990841 , -0.01786499,  0.00695241,\n",
            "        0.15933605, -0.02809027,  0.0147193 ,  0.15072964, -0.00298209,\n",
            "       -0.15610576, -0.05875939,  0.05332009,  0.22004597,  0.1062866 ,\n",
            "        0.09089354,  0.03621432, -0.01376179,  0.07284073, -0.11803743,\n",
            "        0.10290713,  0.17175156,  0.09627068,  0.03114554,  0.07370009,\n",
            "       -0.13480112, -0.00356767,  0.02902903, -0.1969893 , -0.02877663,\n",
            "        0.07093938, -0.06295201, -0.11513643,  0.0131266 ,  0.25525409,\n",
            "        0.15786698, -0.08176979, -0.12105227,  0.18613163, -0.15698513,\n",
            "       -0.01741213,  0.11648855, -0.09973602, -0.18072733, -0.18099687,\n",
            "        0.11777619,  0.41321412,  0.07240836, -0.12010649,  0.02142368,\n",
            "       -0.02828327, -0.08779524,  0.06264971,  0.08057605, -0.10684548,\n",
            "        0.10201148, -0.09868585,  0.10542156,  0.17566845, -0.0384904 ,\n",
            "       -0.02009021,  0.17669271, -0.01935061,  0.04595475,  0.03232023,\n",
            "        0.00336507, -0.07818182,  0.03930726, -0.06453767, -0.03124446,\n",
            "        0.17771938, -0.08328466, -0.06642504,  0.03235259, -0.18346131,\n",
            "        0.12912115, -0.0012145 , -0.07982046, -0.07416697, -0.0216701 ,\n",
            "       -0.06855237, -0.03494355,  0.15650028, -0.26451695,  0.17535141,\n",
            "        0.12025398, -0.04282489,  0.20084912,  0.0512448 ,  0.06830701,\n",
            "        0.05611813, -0.09743866, -0.14430425, -0.10735733,  0.06915177,\n",
            "       -0.03063141,  0.08807868,  0.00318425]), array([-0.14687368,  0.01456255,  0.00958664, -0.0906373 , -0.0347506 ,\n",
            "       -0.02814522, -0.04816662, -0.07201219,  0.18186997, -0.05262711,\n",
            "        0.18903413, -0.01573794, -0.10202901, -0.15238808, -0.04394409,\n",
            "        0.08903156, -0.22752291, -0.15912607,  0.07723728, -0.04753591,\n",
            "        0.03216673, -0.01582479,  0.0131561 ,  0.09124845, -0.22455089,\n",
            "       -0.27669069, -0.10768033, -0.10294095,  0.05011374, -0.02970619,\n",
            "       -0.01691376,  0.08687535, -0.28536659, -0.05618397,  0.04192267,\n",
            "        0.22503185,  0.04101982, -0.02289622,  0.13595706,  0.0723049 ,\n",
            "       -0.12464093, -0.08220944, -0.00466462,  0.3078019 ,  0.16916782,\n",
            "        0.01912043, -0.03434774, -0.03070135,  0.07104126, -0.23741747,\n",
            "        0.1053315 ,  0.13758168,  0.1232184 , -0.00968777,  0.00666855,\n",
            "       -0.1276011 ,  0.05288792,  0.11273243, -0.19587691,  0.0067393 ,\n",
            "       -0.00634798, -0.04833999, -0.02201466, -0.00698339,  0.22678618,\n",
            "        0.15594845, -0.09091264, -0.14867142,  0.22299436, -0.11133648,\n",
            "       -0.03823413,  0.07677037, -0.06632991, -0.15095434, -0.35024399,\n",
            "        0.03913257,  0.42800948,  0.11596572, -0.19073668,  0.04809583,\n",
            "       -0.12053512, -0.00348842,  0.08458771,  0.07046823, -0.1053131 ,\n",
            "        0.07375275, -0.13086224,  0.03368329,  0.16911384,  0.03291678,\n",
            "       -0.06798425,  0.12386519, -0.01227004,  0.03331785,  0.08444626,\n",
            "        0.01747566, -0.03388648,  0.03993034, -0.15609565, -0.03680126,\n",
            "        0.06560834, -0.0336534 , -0.01261547,  0.2136699 , -0.21687877,\n",
            "        0.08618917,  0.05658762, -0.13602597, -0.00094267,  0.00112754,\n",
            "       -0.12152977, -0.07914868,  0.12221392, -0.32238334,  0.13484418,\n",
            "        0.16859089,  0.01711661,  0.19920158,  0.08026381,  0.06231686,\n",
            "       -0.00676179, -0.06984653, -0.12635076, -0.03838142,  0.01344798,\n",
            "       -0.03877921,  0.05556858,  0.02998889])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUm_1fxU7t_u"
      },
      "outputs": [],
      "source": [
        "pip -q install crewai langchain_groq langchain_community duckduckgo-search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "no-EhZT58YU1"
      },
      "outputs": [],
      "source": [
        "from langchain_groq import ChatGroq\n",
        "Groq_llm = ChatGroq(api_key = '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', model = 'gemma-7b-it')\n",
        "from crewai import Crew, Agent, Task, Process\n",
        "from langchain_community.tools import DuckDuckGoSearchRun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lBz6NNh-sqd"
      },
      "outputs": [],
      "source": [
        "import pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiMPvwju8gSs"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import load_tools\n",
        "\n",
        "search_tool = DuckDuckGoSearchRun()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvGVipvo8kwl"
      },
      "outputs": [],
      "source": [
        "import json  # Import the JSON module to parse JSON strings\n",
        "from langchain_core.agents import AgentFinish\n",
        "\n",
        "agent_finishes  = []\n",
        "\n",
        "import json\n",
        "from typing import Union, List, Tuple, Dict\n",
        "from langchain.schema import AgentFinish\n",
        "\n",
        "call_number = 0\n",
        "\n",
        "def print_agent_output(agent_output: Union[str, List[Tuple[Dict, str]], AgentFinish], agent_name: str = 'Generic call'):\n",
        "    global call_number  # Declare call_number as a global variable\n",
        "    call_number += 1\n",
        "    with open(\"crew_callback_logs.txt\", \"a\") as log_file:\n",
        "        if isinstance(agent_output, str):\n",
        "            try:\n",
        "                agent_output = json.loads(agent_output)\n",
        "            except json.JSONDecodeError:\n",
        "                pass\n",
        "\n",
        "        if isinstance(agent_output, list) and all(isinstance(item, tuple) for item in agent_output):\n",
        "            print(f\"-{call_number}----Dict------------------------------------------\", file=log_file)\n",
        "            for action, description in agent_output:\n",
        "                # Print attributes based on assumed structure\n",
        "                print(f\"Agent Name: {agent_name}\", file=log_file)\n",
        "                print(f\"Tool used: {getattr(action, 'tool', 'Unknown')}\", file=log_file)\n",
        "                print(f\"Tool input: {getattr(action, 'tool_input', 'Unknown')}\", file=log_file)\n",
        "                print(f\"Action log: {getattr(action, 'log', 'Unknown')}\", file=log_file)\n",
        "                print(f\"Description: {description}\", file=log_file)\n",
        "                print(\"--------------------------------------------------\", file=log_file)\n",
        "\n",
        "        # Check if the output is a dictionary as in the second case\n",
        "        elif isinstance(agent_output, AgentFinish):\n",
        "            print(f\"-{call_number}----AgentFinish---------------------------------------\", file=log_file)\n",
        "            print(f\"Agent Name: {agent_name}\", file=log_file)\n",
        "            agent_finishes.append(agent_output)\n",
        "            # Extracting 'output' and 'log' from the nested 'return_values' if they exist\n",
        "            output = agent_output.return_values\n",
        "            # log = agent_output.get('log', 'No log available')\n",
        "            print(f\"AgentFinish Output: {output['output']}\", file=log_file)\n",
        "            # print(f\"Log: {log}\", file=log_file)\n",
        "            # print(f\"AgentFinish: {agent_output}\", file=log_file)\n",
        "            print(\"--------------------------------------------------\", file=log_file)\n",
        "\n",
        "        # Handle unexpected formats\n",
        "        else:\n",
        "            # If the format is unknown, print out the input directly\n",
        "            print(f\"-{call_number}-Unknown format of agent_output:\", file=log_file)\n",
        "            print(type(agent_output), file=log_file)\n",
        "            print(agent_output, file=log_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f66hJEI-8_Zi"
      },
      "outputs": [],
      "source": [
        "class material_generator():\n",
        "    def entity_recognizer(self):\n",
        "        return Agent(\n",
        "                role = 'Named Entity Recogniser',\n",
        "                goal = ''' Analyze the textual data and identify and classify\n",
        "                        important information within text data.''',\n",
        "                backstory='''You are a master at understanding the lectures''',\n",
        "                llm = Groq_llm,\n",
        "                verbose=False,\n",
        "                allow_delegation=False,\n",
        "                max_iter=5,\n",
        "                memory=True,\n",
        "                step_callback=lambda x: print_agent_output(x,'Named entity recognition'))\n",
        "\n",
        "    def notes_maker(self):\n",
        "        return Agent(\n",
        "        role = 'Topic researcher agent',\n",
        "        goal='''Analyze the topics given and make a complete notes accordingly.\n",
        "                focus on key ideas don't try to write everything down word-for-word.\n",
        "                Instead, focus on capturing the main points, definitions, arguments, and conclusions.\n",
        "                Be selective: Not all details are essential. Use bullet points, abbreviations, and symbols\n",
        "                to condense information efficiently.Use headings, subheadings, numbering, and indentation to create a clear hierarchy of information. ''',\n",
        "        backstory = '''You are a master in math, physics, chemistry, biology, engineering subjects,\n",
        "                    computer sciences and an expert in preparing study materials for students''',\n",
        "        llm = Groq_llm,\n",
        "        verbose=False,\n",
        "        allow_delegation=False,\n",
        "        memory=True,\n",
        "        tools=[search_tool],\n",
        "        step_callback=lambda x: print_agent_output(x,\"notes_maker\"),)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COiKKk2i9OC3"
      },
      "outputs": [],
      "source": [
        "class task_manager():\n",
        "    # Define your tasks with descriptions and expected outputs\n",
        "    def topic_reco(self, data):\n",
        "        return Task(\n",
        "            description=\"\"\"Conduct a comprehensive analysis and grasp the general topic and identify your learning goals\"\"\",\n",
        "            expected_output= 'a list of topics and learning goals',\n",
        "            output_file=f\"topics.txt\",\n",
        "            agent=ner_agent\n",
        "            )\n",
        "\n",
        "    def material_maker(self, data):\n",
        "        return Task(\n",
        "            description='''Analyze the topics given and make a complete notes accordingly.\n",
        "                focus on key ideas don't try to write everything down word-for-word.\n",
        "                Instead, focus on captu+ring the main points, definitions, arguments, and conclusions.\n",
        "                Be selective: Not all details are essential. Use bullet points, abbreviations, and symbols\n",
        "                to condense information efficiently.Use headings, subheadings, numbering, and indentation to create a clear hierarchy of information.Pleasen do not repeat sentences''',\n",
        "            expected_output=\"\"\"A large chuck of prepared notes\"\"\",\n",
        "            context = [topic_model],\n",
        "            output_file=f\"output_list.txt\",\n",
        "            agent=data_gen\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9u_ZeRcr9mdn"
      },
      "outputs": [],
      "source": [
        "\n",
        "def generator(data):\n",
        "      agents = material_generator()\n",
        "      tasks = task_manager()\n",
        "  #agents\n",
        "      ner_agent = agents.entity_recognizer()\n",
        "      data_gen = agents.notes_maker()\n",
        "\n",
        "  #tasks\n",
        "      topic_model = tasks.topic_reco(data)\n",
        "      notes = tasks.material_maker(data)\n",
        "      crew = Crew(\n",
        "        agents=[ner_agent,data_gen],\n",
        "        tasks=[topic_model, notes],\n",
        "        verbose = 2,\n",
        "        process = Process.sequential,\n",
        "        full_output=True,\n",
        "        share_crew = False,\n",
        "        step_callback = lambda x: print_agent_output(x,\"MasterCrew Agent\"))\n",
        "      results = crew.kickoff()\n",
        "      d1 = list(results.values())\n",
        "      tasks = d1[1]\n",
        "      full_dictionary = []\n",
        "      for i in tasks:\n",
        "          newdict = dict(i)\n",
        "          full_dictionary.append(newdict)\n",
        "      return full_dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0z7bUHp_cjN"
      },
      "outputs": [],
      "source": [
        "pip install reportLab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lkb8im3G-jNs"
      },
      "outputs": [],
      "source": [
        "notes = generator(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dmak3Pw0CfYQ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "https://153d-34-91-237-152.ngrok-free.app"
      ],
      "metadata": {
        "id": "nfTS51KjCRDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GU2WezJQ32dG"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iS05R4gvZNxd"
      },
      "outputs": [],
      "source": [
        "print(public_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W52wfYgHXFNO"
      },
      "outputs": [],
      "source": [
        "pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHmX6wv4xTAY"
      },
      "outputs": [],
      "source": [
        "!pip install pyngrok\n",
        "from pyngrok import ngrok\n",
        "\n",
        "!ngrok config add-authtoken 2fh3RRrTOnb4LIpFOyDh31DajTd_7T3TkvLzcjBaa9VBGhXw4\n",
        "\n",
        "public_url = ngrok.connect(5000)\n",
        "print(\"Print URL:\", public_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wml3e9yUjxGX"
      },
      "outputs": [],
      "source": [
        "pip install face_recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDhP9RW5OJVz"
      },
      "outputs": [],
      "source": [
        "import face_recognition as fr\n",
        "import cv2\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRZyhxXJ17GR"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import os\n",
        "\n",
        "class VideoPreprocessor:\n",
        "    def __init__(self, directory, video_path):\n",
        "        self.directory = directory\n",
        "        self.video_path = video_path\n",
        "        self.fps = None\n",
        "        self.frame_count = 0\n",
        "        self.extracted_frame_count = 0\n",
        "\n",
        "    def empty_folder(self):\n",
        "        for file in os.listdir(self.directory):\n",
        "            file_path = os.path.join(self.directory, file)\n",
        "            if os.path.isfile(file_path):\n",
        "                os.remove(file_path)\n",
        "        return True\n",
        "\n",
        "    def extract_frames_per_second(self):\n",
        "        try:\n",
        "            cap = cv.VideoCapture(self.video_path)\n",
        "            if not cap.isOpened():\n",
        "                raise IOError(\"Error opening video!\")\n",
        "\n",
        "            self.fps = cap.get(cv.CAP_PROP_FPS)\n",
        "            if self.fps <= 0:\n",
        "                raise ValueError(\"Invalid FPS value.\")\n",
        "\n",
        "            if self.empty_folder():\n",
        "                while True:\n",
        "                    ret, frame = cap.read()\n",
        "\n",
        "                    if not ret:\n",
        "                        print(\"End of video reached.\")\n",
        "                        break\n",
        "\n",
        "                    # Extract one frame per second\n",
        "                    if self.frame_count % int(self.fps) == 0:\n",
        "                        filename = f\"{self.directory}/frame_{self.extracted_frame_count}.jpg\"\n",
        "                        cv.imwrite(filename, frame)\n",
        "                        self.extracted_frame_count += 1\n",
        "\n",
        "                    self.frame_count += 1\n",
        "\n",
        "                print(f\"Extracted {self.extracted_frame_count} frames to {self.directory}\")\n",
        "\n",
        "        except IOError as e:\n",
        "            print(f\"IOError: {e}\")\n",
        "        except ValueError as e:\n",
        "            print(f\"ValueError: {e}\")\n",
        "        finally:\n",
        "            cap.release()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nwvo6NqNYoUu"
      },
      "source": [
        "CLASSES TEST\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ip5myxmsYmrt"
      },
      "outputs": [],
      "source": [
        "import face_recognition as fr\n",
        "import cv2\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "class FaceRecognition:\n",
        "    def __init__(self, frames_dir, known_face_encodings, student_dic):\n",
        "        self.frames_dir = frames_dir\n",
        "        self.known_face_encodings = known_face_encodings\n",
        "        self.students = student_dic\n",
        "\n",
        "        csm_students = list(self.students.keys())\n",
        "\n",
        "    def load_image_paths(self):\n",
        "        image_paths = [os.path.join(self.frames_dir, filename) for filename in os.listdir(self.frames_dir) if filename.lower().endswith('.jpg')]\n",
        "        return image_paths\n",
        "\n",
        "    def find_faces(self, image_paths):\n",
        "        face_locations = []\n",
        "        face_encodings = []\n",
        "\n",
        "        for path in image_paths:\n",
        "            frame = fr.load_image_file(path)\n",
        "            rgb_frame = frame[:, :, ::-1]  # Convert BGR to RGB\n",
        "\n",
        "            face_locations = fr.face_locations(rgb_frame, number_of_times_to_upsample=1, model='hog')\n",
        "            face_encodings_for_frame = fr.face_encodings(frame, face_locations)\n",
        "\n",
        "            face_encodings.extend(face_encodings_for_frame)\n",
        "\n",
        "        return face_encodings\n",
        "\n",
        "\n",
        "\n",
        "    def cosine_similarity(self, vector_a, vector_b):\n",
        "        vector_a = np.array(vector_a, dtype=float)\n",
        "        vector_b = np.array(vector_b, dtype=float)\n",
        "        dot_product = np.dot(vector_a, vector_b)\n",
        "        magnitude_a = np.linalg.norm(vector_a)\n",
        "        magnitude_b = np.linalg.norm(vector_b)\n",
        "\n",
        "        if magnitude_a == 0 or magnitude_b == 0:\n",
        "            return 0\n",
        "\n",
        "        cosine_similarity_value = dot_product / (magnitude_a * magnitude_b)\n",
        "        return cosine_similarity_value\n",
        "\n",
        "    def compare_faces(self, video_face_encodings):\n",
        "        similarities = []\n",
        "        student_names = []\n",
        "        csm_students = list(self.students.keys())\n",
        "\n",
        "        for y in video_face_encodings:\n",
        "            nec = [self.cosine_similarity(y, x) for x in self.known_face_encodings]\n",
        "            similarities.append(nec)\n",
        "\n",
        "        for x in similarities:\n",
        "            student_names.append(csm_students[np.argmax(x)])\n",
        "\n",
        "        return list(set(student_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdIH_8kfmDsg"
      },
      "outputs": [],
      "source": [
        "from Face_recog_m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbXE2VJvdn71"
      },
      "outputs": [],
      "source": [
        "from flask import *\n",
        "from VideoPreoprocess import VideoPreprocessor\n",
        "from Face_recog_methods_2 import FaceRecognition\n",
        "import sqlite3\n",
        "import numpy as np\n",
        "import os\n",
        "app = Flask(__name__)\n",
        "app.secret_key=\"I_SAVE_GOTHAM\"\n",
        "@app.route('/')\n",
        "def videoUploadFile():\n",
        "    return render_template('index.html')\n",
        "\n",
        "ALLOWED_EXTENSIONS = ['mp4']\n",
        "\n",
        "def allowed_file(filename):\n",
        "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
        "\n",
        "@app.route(\"/upload\",methods = ['POST',\"GET\"])\n",
        "def uploadStudents():\n",
        "    if 'video' not in request.files:\n",
        "        return  jsonify(\"No Video Found\")\n",
        "    video = request.files['video']\n",
        "    if video.filename == \"\":\n",
        "        return jsonify(\"No File Selected\")\n",
        "    if video and allowed_file(video.filename):\n",
        "        video.save(video.filename)\n",
        "        video_object = VideoPreprocessor(\"Face-Attendance-Server-main/Frames\",video_path=video.filename)\n",
        "        if video_object.empty_folder():\n",
        "            video_object.extract_frames_per_second()\n",
        "            studentdetails,known_encodings = fetchFromDataBase()\n",
        "            face_object = FaceRecognition(\"Face-Attendance-Server-main/Frames\",known_encodings,studentdetails)\n",
        "            new_image_paths = face_object.load_image_paths()\n",
        "            new_face_encodings = face_object.find_faces(new_image_paths)\n",
        "            attendees_list = face_object.compare_faces(new_face_encodings)\n",
        "            print(attendees_list)\n",
        "            return jsonify(attendees_list)\n",
        "        return jsonify(\"Error in emptying the Folder\")\n",
        "    return jsonify(\"Invalid type in the File \")\n",
        "def fetchFromDataBase():\n",
        "    with sqlite3.connect(\"Attendance.db\") as conn:\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"SELECT * FROM USERS\")\n",
        "        student_dict = {}\n",
        "        new_Face_Encodings = []\n",
        "        for i in cursor :\n",
        "            student_dict[i[1]] = i[0]\n",
        "            new_Face_Encodings.append([float(j) for j in i[2].split(\"/\") ])\n",
        "    return student_dict,new_Face_Encodings\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(debug=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGbw6PFidiuH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wH5Hjh4bMBc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}